{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d8fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 Chain of Thought를 기반으로 한 인공지능 언어 모델로, 문제 해결 과정을 이해하고 추론하는 능력을 갖추고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, SimpleJsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_classic import hub\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen2.5-3b-instruct-q4_k_m.gguf\",\n",
    "    base_url=\"http://localhost:8002/v1\",\n",
    "    api_key=\"EMPTY\",   # 실제로 사용되지 않음\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"LangChain이 무엇인지 한 문장으로 설명해줘\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400dfc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    당신은 AI 튜터입니다.\n",
      "    아래 질문에 대해 한 문장으로 명확하게 한글로 답하세요.\n",
      "    \n",
      "    질문: LangChain이 왜 필요한가?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "#  PromptTemplate과 ChatPromptTemplate은 동일하게 동작하나, 단일문자열 or 역할기반 메시지의 차이임.\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    당신은 AI 튜터입니다.\n",
    "    아래 질문에 대해 한 문장으로 명확하게 한글로 답하세요.\n",
    "    \n",
    "    질문: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(question=\"LangChain이 왜 필요한가?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c85e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ontology는 정보의 구조와 의미를 정의하고 관계를 명확히 하는 체계적인 모델 또는 체계입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 68, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5-3b-instruct-q4_k_m.gguf', 'system_fingerprint': 'b7654-3333951d8', 'id': 'chatcmpl-tbi8iJCUnySyLWL68p0Y9R7NLmqpZUAp', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b9910-2c55-7371-abb8-087b29ff5726-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 33, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(question=\"Ontology가 무엇인가?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc7fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a professional translator.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Translate the following text to Korean:\\nHello world', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional translator.\"),\n",
    "    (\"human\", \"Translate the following text to Korean:\\n{text}\")\n",
    "])\n",
    "\n",
    "prompt.format_messages(text=\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4470be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello is translated to Korean as \"안녕하세요\" (annyeonghaseyo).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5-3b-instruct-q4_k_m.gguf', 'system_fingerprint': 'b7654-3333951d8', 'id': 'chatcmpl-35YCXEEKqwVgBlEvPOvzHZw5rhFcVcqm', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b990d-dc2d-7a02-98ac-c57413dea261-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 27, 'output_tokens': 21, 'total_tokens': 48, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"text\": \"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다. 독도는 경상북도 울릉군에 속해 있으며, 대한민국의 영토입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# messages = chat_prompt.invoke(\n",
    "#     {\"question\": \"LangChain은 무엇인가요?\"}\n",
    "# )\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "response = chain.invoke({\"question\": \"독도는 어느 나라 땅 인가요?\"})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534b7ae",
   "metadata": {},
   "source": [
    "StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다. 독도는 경상북도 울릉군에 속해 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# outputparser 추가\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | output_parser\n",
    "result = chain.invoke({\"question\": \"독도는 어느 나라 땅 인가요?\"})\n",
    "\n",
    "print(result)       # 출력은 문자열(content 속성 없음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9042af7",
   "metadata": {},
   "source": [
    "RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41082f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다.它是韩国的领土.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | chat_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"독도는 어느 나라 땅 인가요?\")     # {\"question\": \"...\"} 형태로 감싸지 않음 → RunnablePassthrough에서 다음 단계로 그대로 전달\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd5a18",
   "metadata": {},
   "source": [
    "OutputParser 활용 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'country': '대한민국', 'island_name': '독도', 'coordinates': {'latitude': '36.2500', 'longitude': '126.8000'}}, 'history': {'establishment': '1416년', 'establisher': '조선 왕조', 'significance': '국土의 확장과 통일의象征'}, 'current_status': {'administered_by': '대한민국 정부', 'accessibility': '독도는 현재 일반 관광객의 접근이 제한됩니다.'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 정보를 JSON으로만 출력하는 AI입니다.\"),\n",
    "    (\"user\", \"질문에 답하세요.\\n\\n{format_instructions}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "chain = json_prompt | llm | parser \n",
    "result = chain.invoke(\n",
    "    {\"question\": \"독도는 어느 나라 땅 인가요? 국가와 위치, 역사 등을 포함해서 알려주세요.\",\n",
    "     \"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 결과를 보면 알 수 있듯이, llm이 판단하여 JSON 형식으로 출력을 생성함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce70a92",
   "metadata": {},
   "source": [
    "Pydantic OutputParser (Custom Setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80780e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic 모델 정의\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    summary: str = Field(description=\"한 문장 요약\")\n",
    "    keywords: list[str] = Field(description=\"핵심 키워드 목록\")\n",
    "\n",
    "\n",
    "# Parser 생성\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Answer)\n",
    "\n",
    "\n",
    "# Prompt 구성\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"출력을 반드시 지정된 형식으로 작성하세요.\"),\n",
    "    (\"user\", \"{format_instructions}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"question\": \"LangChain의 역할을 설명해줘\",\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef245ec8",
   "metadata": {},
   "source": [
    "SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a4ecc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AI': {'Strengths': [{'Name': 'Speed and Efficiency', 'Description': 'AI can process and analyze large amounts of data much faster than humans.'}, {'Name': 'Accuracy', 'Description': 'AI can perform tasks with high accuracy and consistency, reducing human error.'}, {'Name': 'Automation', 'Description': 'AI can automate repetitive and time-consuming tasks, freeing up human resources.'}, {'Name': 'Insight and Pattern Recognition', 'Description': 'AI can identify patterns and insights in data that might be difficult for humans to detect.'}], 'Weaknesses': [{'Name': 'Lack of Creativity', 'Description': 'AI lacks creativity and cannot generate new ideas or concepts.'}, {'Name': 'Limited Understanding of Context', 'Description': 'AI may struggle with tasks that require understanding of context and human emotions.'}, {'Name': 'Bias and Fairness', 'Description': 'AI systems can be biased if the data they are trained on is biased.'}, {'Name': 'Dependence on Data Quality', 'Description': 'AI systems perform better when trained on high-quality data, which may not always be available.'}]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | parser\n",
    "\n",
    "result = chain.invoke(\n",
    "    {\"question\": \"AI의 장단점을 JSON으로 정리해줘\"}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72921cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'thought': ''}\n",
      "{'thought': '독'}\n",
      "{'thought': '독도'}\n",
      "{'thought': '독도는'}\n",
      "{'thought': '독도는 대한'}\n",
      "{'thought': '독도는 대한민'}\n",
      "{'thought': '독도는 대한민국'}\n",
      "{'thought': '독도는 대한민국의'}\n",
      "{'thought': '독도는 대한민국의 땅'}\n",
      "{'thought': '독도는 대한민국의 땅으로'}\n",
      "{'thought': '독도는 대한민국의 땅으로,'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': ''}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅입니다'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅입니다.'}\n"
     ]
    }
   ],
   "source": [
    "# SimleJsonOutputParser는 스트리밍 방식으로 출력 가능\n",
    "\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"반드시 JSON 형식으로만 응답하세요.\"),\n",
    "    (\"user\", \"\"\"\n",
    "질문에 답하세요.\n",
    "\n",
    "JSON 형식:\n",
    "{{\n",
    "  \"thought\": \"...\",\n",
    "  \"answer\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "\n",
    "### 주의! Prompt에 JSON / dict / code block을 넣을 경우 {}는 항상 {{}}로 쓴다(이스케이프) ###\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "for chunk in chain.stream({\"question\": \"독도는 어느 나라 땅 인가요?\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d520f",
   "metadata": {},
   "source": [
    "ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c481e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저축을 늘리기 위해 매달 일정 금액을 자동으로 저축하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# <이전 대화를 포함한 메시지 전달>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 정의: 금융 상담 역할\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 금융 상담사입니다. 사용자에게 최선의 금융 조언을 제공합니다.\"),\n",
    "        (\"placeholder\", \"{messages}\"),  # 대화 이력 추가\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트와 모델을 연결하여 체인 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 이전 대화를 포함한 메시지 전달\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"human\", \"저축을 늘리기 위해 무엇을 할 수 있나요?\"),  # 사용자의 첫 질문\n",
    "            (\"ai\", \"저축 목표를 설정하고, 매달 자동 이체로 일정 금액을 저축하세요.\"),  # 챗봇의 답변\n",
    "            (\"human\", \"방금 뭐라고 했나요?\"),  # 사용자의 재확인 질문\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(ai_msg.content)  # 챗봇의 응답 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5af860ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저축을 늘리기 위해 매달 일정 금액을 자동으로 저축하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# <`ChatMessageHistory`를 사용한 메시지 관리>\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# 대화 이력 저장을 위한 클래스 초기화\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "# 사용자 메시지 추가\n",
    "chat_history.add_user_message(\"저축을 늘리기 위해 무엇을 할 수 있나요?\")\n",
    "chat_history.add_ai_message(\"저축 목표를 설정하고, 매달 자동 이체로 일정 금액을 저축하세요.\")\n",
    "\n",
    "# 새로운 질문 추가 후 다시 체인 실행\n",
    "chat_history.add_user_message(\"방금 뭐라고 했나요?\")\n",
    "ai_response = chain.invoke({\"messages\": chat_history.messages})\n",
    "print(ai_response.content)  # 챗봇은 이전 메시지를 기억하여 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278e2ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저축을 늘리는 방법은 여러 가지가 있습니다. 아래에 몇 가지를 제안해 드릴게요:\\n\\n1. 예산 관리: 현재 소비 패턴을 분석하고 필요 이상으로 지출하지 않도록 관리하세요. \\n\\n2. 금융 상품 비교: 다양한 저축 상품을 비교해 보세요. 예를 들어 저축 예금, 저축 상품, 펀드 등 다양한 옵션이 있습니다.\\n\\n3. 자동 저축 설정: 예금 계좌에 자동으로 저축을 설정하면, 지출이 일어날 때마다 자동으로 저축이 이루어지게 됩니다.\\n\\n4. 금융 상담: 전문가의 조언을 받는 것도 좋은 방법입니다. 금융 상담사나 투자 전문가와 상담을 통해 올바른 금융 결정을 내릴 수 있습니다.\\n\\n5. 재무 계획 작성: 목표와 계획을 명확하게 정리하면, 금융 상황을 더 잘 이해하고 관리할 수 있습니다.\\n\\n6. 저축률 향상: 현재의 저축률을 높이는 것도 중요합니다. 예를 들어, 현재 5%의 저축률이라면 10%로 높이는 것이 좋습니다.\\n\\n7. 금융 교육: 금융에 대한 이해를 높이는 것도 중요합니다. 다양한 자료를 찾아보거나, 관련 강의나 세미나에 참석하는 것도 도움이 될 수 있습니다.\\n\\n이러한 방법들을 활용하면 저축률을 높일 수 있을 것입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <` RunnableWithMessageHistory`를 사용한 메시지 관리>\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# 시스템 메시지와 대화 이력을 사용하는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 금융 상담사입니다. 모든 질문에 최선을 다해 답변하십시오.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),  # 이전 대화 이력\n",
    "        (\"human\", \"{input}\"),  # 사용자의 새로운 질문\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 대화 이력을 관리할 체인 설정\n",
    "chat_history = ChatMessageHistory()\n",
    "chain = prompt | llm\n",
    "\n",
    "# RunnableWithMessageHistory 클래스를 사용해 체인을 감쌉니다\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,  # 세션 ID에 따라 대화 이력을 불러오는 함수\n",
    "    input_messages_key=\"input\",  # 입력 메시지의 키 설정\n",
    "    history_messages_key=\"chat_history\",  # 대화 이력의 키 설정\n",
    ")\n",
    "\n",
    "# 질문 메시지 체인 실행\n",
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"저축을 늘리기 위해 무엇을 할 수 있나요?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b961861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송합니다, 제가前에您刚刚說了什麼?을 이해하지 못했습니다. 다시 말씀해 주시면 감사하겠습니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 입력 메시지를 추가하고 체인을 실행\n",
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"내가 방금 뭐라고 했나요?\"},  # 사용자의 질문\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}}  # 세션 ID 설정\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26974efd",
   "metadata": {},
   "source": [
    "Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94682de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='물론입니다. 5년 내에 집을 사는 계획을 세우는데 필요한 재정 계획을 세우는 것은 매우 중요합니다. 아래에 몇 가지 기본적인 팁을 제공해 드릴게요.\\n\\n1. **재정 분석**: 현재의 재정 상태를 분석합니다. 월급, 소득, 비용, 저축률 등을 파악합니다. 이를 통해 필요한 금액과 가능한 재정 상태를 파악할 수 있습니다.\\n\\n2. **목표 설정**: 집을 사는 목표를 명확히 설정합니다. 예를 들어, 특정 지역의 특정 가격대의 집을 사는 것이 목표라면, 이를 명확히 설정해야 합니다.\\n\\n3. **재정 계획**: 목표를 달성하기 위한 재정 계획을 세웁니다. 예를 들어, 월간 또는 월간 저축률을 설정하고, 이에 따라 필요한 금액을 계산합니다.\\n\\n4. **투자 계획**: 재정 계획을 위한 투자 계획을 세웁니다. 예를 들어, 주식, 부동산, 펀드 등 다양한 투자 방법을 고려할 수 있습니다.\\n\\n5. **재정 관리**: 재정 관리를 통해 목표를 달성하는 데 필요한 모든 요소를 관리합니다. 예를 들어, 월간 예산을 설정하고, 필요에 따라 재정을 조절할 수 있습니다.\\n\\n6. **재정 보험**: 재정 보험을 구매하여 재정 위험을 관리합니다. 예를 들어, 재정 위험을 감소시키는 보험을 구매하거나, 재정 위험을 관리하는 방법을 배우는 것이 좋습니다.\\n\\n7. **재정 교육**: 재정 관리를 위한 교육을 받습니다. 재정 관리를 위한 다양한 교육 자료나 워크숍 등을 찾아보세요.\\n\\n이러한 계획을 세우는 것은 쉽지 않을 것입니다. 하지만, 꾸준히 노력하면 5년 후에 집을 사는 것이 가능합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 457, 'prompt_tokens': 112, 'total_tokens': 569, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5-3b-instruct-q4_k_m.gguf', 'system_fingerprint': 'b7654-3333951d8', 'id': 'chatcmpl-vzhhpLRlm1FwCEKmWw0pybUlrxTTtrB3', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b9952-1246-7990-a7a2-0447e1425518-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 112, 'output_tokens': 457, 'total_tokens': 569, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <메시지 트리밍 예제>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# 메시지 트리밍 유틸리티 설정\n",
    "trimmer = trim_messages(strategy=\"last\", max_tokens=2, token_counter=len)\n",
    "\n",
    "# 트리밍된 대화 이력과 함께 체인 실행\n",
    "chain_with_trimming = (\n",
    "    RunnablePassthrough.assign(chat_history=itemgetter(\"chat_history\") | trimmer)\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 트리밍된 대화 이력을 사용하는 체인 설정\n",
    "chain_with_trimmed_history = RunnableWithMessageHistory(\n",
    "    chain_with_trimming,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 새로운 대화 내용 추가 후 체인 실행\n",
    "chain_with_trimmed_history.invoke(\n",
    "    {\"input\": \"저는 5년 내에 집을 사기 위해 어떤 재정 계획을 세워야 하나요?\"},  # 사용자의 질문\n",
    "    {\"configurable\": {\"session_id\": \"finance_session_1\"}}  # 세션 ID 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "925617c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송합니다, 제가前에与えた回答が適切ではありませんでした。5년以内に家を購入するための財政計画を立てることについてアドバイスを提供しました。もう一度質問해 주시면, 더 도움이 될 것 같습니다。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 입력 메시지를 추가하고 체인을 실행\n",
    "chain_with_trimmed_history.invoke(\n",
    "    {\"input\": \"내가 방금 뭐라고 했나요?\"},  # 사용자의 질문\n",
    "    {\"configurable\": {\"session_id\": \"finance_session_1\"}}  # 세션 ID 설정\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816f4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <이전 대화 요약 내용 기반으로 답변하기>\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    # 대화를 요약하기 위한 프롬프트 템플릿 설정\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),  # 이전 대화 이력\n",
    "            (\n",
    "                \"user\",\n",
    "                \"이전 대화를 요약해 주세요. 가능한 한 많은 세부 정보를 포함하십시오.\",  # 요약 요청 메시지\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 요약 체인 생성 및 실행\n",
    "    summarization_chain = summarization_prompt | llm\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "    chat_history.clear()  # 요약 후 이전 대화 삭제\n",
    "    chat_history.add_message(summary_message)  # 요약된 메시지를 대화 이력에 추가\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1df7db8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송합니다, 제가 잘못 이해했습니다. 재정적 조언에 대해 구체적으로 질문해 주셨다면, 그 질문에 답변 드리겠습니다. 예를 들어, 집을 사는 목표를 가지고 계획을 세우는 방법, 월간 저축률 계산 방법, 재정 위험 관리 방법 등에 대한 질문이 있으면 답변 드릴 수 있습니다. 어떤 재정적 상황에 대한 조언이 필요하신지 좀 더 구체적으로 알려주시면 감사하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# 대화 요약을 처리하는 체인 설정\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")\n",
    "\n",
    "# 요약된 대화를 기반으로 새로운 질문에 응답\n",
    "print(chain_with_summarization.invoke(\n",
    "    {\"input\": \"저에게 어떤 재정적 조언을 해주셨나요?\"},  # 사용자의 질문\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}}  # 세션 ID 설정\n",
    ").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06379b56",
   "metadata": {},
   "source": [
    "Few Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecd7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 주식 투자와 예금 중 어느 것이 더 수익률이 높은가?\n",
      "답변: \n",
      "후속 질문이 필요한가요: 네.\n",
      "후속 질문: 주식 투자의 평균 수익률은 얼마인가요?\n",
      "중간 답변: 주식 투자의 평균 수익률은 연 7%입니다.\n",
      "후속 질문: 예금의 평균 이자율은 얼마인가요?\n",
      "중간 답변: 예금의 평균 이자율은 연 1%입니다.\n",
      "따라서 최종 답변은: 주식 투자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <`PromptTemplate`를 이용한 퓨샷 프롬프트>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 질문과 답변을 포맷하는 프롬프트 템플릿 정의\n",
    "example_prompt = PromptTemplate.from_template(\"질문: {question}\\n답변: {answer}\")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"주식 투자와 예금 중 어느 것이 더 수익률이 높은가?\",\n",
    "        \"answer\": \"\"\"\n",
    "후속 질문이 필요한가요: 네.\n",
    "후속 질문: 주식 투자의 평균 수익률은 얼마인가요?\n",
    "중간 답변: 주식 투자의 평균 수익률은 연 7%입니다.\n",
    "후속 질문: 예금의 평균 이자율은 얼마인가요?\n",
    "중간 답변: 예금의 평균 이자율은 연 1%입니다.\n",
    "따라서 최종 답변은: 주식 투자\n",
    "\"\"\",\n",
    "    } ,\n",
    "    {\n",
    "        \"question\": \"부동산과 채권 중 어느 것이 더 안정적인 투자처인가?\",\n",
    "        \"answer\": \"\"\"\n",
    "후속 질문이 필요한가요: 네.\n",
    "후속 질문: 부동산 투자의 위험도는 어느 정도인가요?\n",
    "중간 답변: 부동산 투자의 위험도는 중간 수준입니다.\n",
    "후속 질문: 채권의 위험도는 어느 정도인가요?\n",
    "중간 답변: 채권의 위험도는 낮은 편입니다.\n",
    "따라서 최종 답변은: 채권\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(example_prompt.invoke(examples[0]).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e052ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 주식 투자와 예금 중 어느 것이 더 수익률이 높은가?\n",
      "답변: \n",
      "후속 질문이 필요한가요: 네.\n",
      "후속 질문: 주식 투자의 평균 수익률은 얼마인가요?\n",
      "중간 답변: 주식 투자의 평균 수익률은 연 7%입니다.\n",
      "후속 질문: 예금의 평균 이자율은 얼마인가요?\n",
      "중간 답변: 예금의 평균 이자율은 연 1%입니다.\n",
      "따라서 최종 답변은: 주식 투자\n",
      "\n",
      "\n",
      "질문: 부동산과 채권 중 어느 것이 더 안정적인 투자처인가?\n",
      "답변: \n",
      "후속 질문이 필요한가요: 네.\n",
      "후속 질문: 부동산 투자의 위험도는 어느 정도인가요?\n",
      "중간 답변: 부동산 투자의 위험도는 중간 수준입니다.\n",
      "후속 질문: 채권의 위험도는 어느 정도인가요?\n",
      "중간 답변: 채권의 위험도는 낮은 편입니다.\n",
      "따라서 최종 답변은: 채권\n",
      "\n",
      "\n",
      "질문: 부동산 투자의 장점은 무엇인가?\n"
     ]
    }
   ],
   "source": [
    "# <`FewShotPromptTemplate` 를 이용한 퓨샷 프롬프트>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "# FewShotPromptTemplate 생성\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"질문: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "# '부동산 투자' 주제로 프롬프트 호출 및 출력\n",
    "print(\n",
    "    prompt.invoke({\"input\": \"부동산 투자의 장점은 무엇인가?\"}).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4a5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wind9\\AppData\\Local\\Temp\\ipykernel_22324\\3617487609.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d408de078e4a58b8a29b6129d9c258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm_serving\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\llm_serving\\llm_servingmodels\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da75b8d7ffa4e36a294bf62aa1231a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd89169718445ddaace624a4d5567b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d0c417e41d4821ba6f0aa55b53f1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd76e0c941c344a4a5a609e7a83a59e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b4643aa9ed48e392c2650e1f6f0957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453f4193c2584370a818426f0943240e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc3c6ddaab5408ca73584ed557acb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104fd33dc25541fba990d98ce75fd959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60035a6219df4f5a8c4b81e476eb301c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39966cc08a684728950f7b4c4f6d10f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력과 가장 유사한 예제: 부동산 투자의 장점은 무엇인가?\n",
      "\n",
      "\n",
      "question: 부동산과 채권 중 어느 것이 더 안정적인 투자처인가?\n",
      "answer: \n",
      "후속 질문이 필요한가요: 네.\n",
      "후속 질문: 부동산 투자의 위험도는 어느 정도인가요?\n",
      "중간 답변: 부동산 투자의 위험도는 중간 수준입니다.\n",
      "후속 질문: 채권의 위험도는 어느 정도인가요?\n",
      "중간 답변: 채권의 위험도는 낮은 편입니다.\n",
      "따라서 최종 답변은: 채권\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <예제 선택기를 이용한 퓨샷 프롬프트>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# # 예제 선택기 초기화\n",
    "# example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "#     examples,  # 사용할 예제 목록\n",
    "#     OpenAIEmbeddings(api_key=api_key),  # 임베딩 생성에 사용되는 클래스\n",
    "#     Chroma,  # 임베딩을 저장하고 유사도 검색을 수행하는 벡터 스토어 클래스\n",
    "#     k=1,  # 선택할 예제의 수\n",
    "# )\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,      # 사용할 예제 목록\n",
    "    embeddings,    # 임베딩 생성에 사용되는 클래스\n",
    "    Chroma,        # 임베딩을 저장하고 유사도 검색을 수행하는 벡터 스토어 클래스\n",
    "    k=1,           # 선택할 예제의 수\n",
    ")\n",
    "\n",
    "\n",
    "# 입력과 가장 유사한 예제 선택\n",
    "question = \"부동산 투자의 장점은 무엇인가?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "# 선택된 예제 출력\n",
    "print(f\"입력과 가장 유사한 예제: {question}\")\n",
    "for example in selected_examples:\n",
    "    print(\"\\n\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3629e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <퓨샷 프롬프트 AI 모델 적용>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 예제 프롬프트 템플릿 생성\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"질문: {question}\\n답변: {answer}\"\n",
    ")\n",
    "\n",
    "# 퓨샷 프롬프트 템플릿 설정\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    prefix=\"다음은 금융 관련 질문과 답변의 예시입니다:\",\n",
    "    suffix=\"질문: {input}\\n답변:\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e099fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부동산 투자의 장점은 다음과 같습니다:\n",
      "\n",
      "1. **재산 증가**: 부동산은 일반적으로 시간이 지날수록 가치가 증가합니다.\n",
      "2. **재무적 안정성**: 부동산은 장기적으로 보유하면 매입 가격과 비교해 매각 가격이 상승하는 경향이 있습니다.\n",
      "3. **수익 창출**: 부동산은 임대료를 통해 수익을 얻을 수 있습니다.\n",
      "4. **투자 다양화**: 부동산 투자는 다른 투자 형태와 함께 다양화된 투자를 할 수 있습니다.\n",
      "5. **재무레버리지 활용**: 부동산 투자는 장기적으로 보유하면 재무레버리지를 활용하여 더 큰 수익을 얻을 수 있습니다.\n",
      "\n",
      "하지만 부동산 투자는 부동산 가격 변동성, 관리 비용, 세금 부담 등 다양한 위험 요소가 존재합니다. 따라서 투자 전에는 충분한 조사를 통해 적절한 투자 결정을 내릴 필요가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# AI 모델 설정\n",
    "# model = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "\n",
    "# 체인 구성 및 실행\n",
    "# chain = prompt | model  # RunnableSequence를 사용하여 체인 연결\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"부동산 투자의 장점은 무엇인가?\"})  # invoke 메서드 사용\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d148a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['lazy_prompt', 'task'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hardkothari', 'lc_hub_repo': 'prompt-maker', 'lc_hub_commit_hash': 'c5db8eeefa7be4862a9599b759608dd10ee53f53910838f69abb5ab31c257c2d'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert Prompt Writer for Large Language Models.\\n\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['lazy_prompt', 'task'], input_types={}, partial_variables={}, template='Your goal is to improve the prompt given below for {task} :\\n--------------------\\n\\nPrompt: {lazy_prompt}\\n\\n--------------------\\n\\nHere are several tips on writing great prompts:\\n\\n-------\\n\\nStart the prompt by stating that it is an expert in the subject.\\n\\nPut instructions at the beginning of the prompt and use ### or to separate the instruction and context \\n\\nBe specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc \\n\\n---------\\n\\nHere\\'s an example of a great prompt:\\n\\nAs a master YouTube content creator, develop an engaging script that revolves around the theme of \"Exploring Ancient Ruins.\"\\n\\nYour script should encompass exciting discoveries, historical insights, and a sense of adventure.\\n\\nInclude a mix of on-screen narration, engaging visuals, and possibly interactions with co-hosts or experts.\\n\\nThe script should ideally result in a video of around 10-15 minutes, providing viewers with a captivating journey through the secrets of the past.\\n\\nExample:\\n\\n\"Welcome back, fellow history enthusiasts, to our channel! Today, we embark on a thrilling expedition...\"\\n\\n-----\\n\\nNow, improve the prompt.\\n\\nIMPROVED PROMPT:'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <랭체인 허브의 특정 프롬프트 불러오기>\n",
    "# pip install langchain-classic\n",
    "from langchain_classic import hub\n",
    "\n",
    "# 최신 버전의 프롬프트 불러오기\n",
    "prompt = hub.pull(\"hardkothari/prompt-maker\")\n",
    "# 특정 버전의 프롬프트 불러오기\n",
    "hub.pull(\"hardkothari/prompt-maker\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_serving",
   "language": "python",
   "name": "llm_serving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
