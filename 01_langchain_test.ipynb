{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d8fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76576c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"qwen2.5-3b-instruct-q4_k_m.gguf\",\n",
    "    base_url=\"http://localhost:8002/v1\",\n",
    "    api_key=\"EMPTY\",   # 실제로 사용되지 않음\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc5dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 Chain of Reasoning with Language Models을 의미하며, 여러 언어 모델을 연결하여 문제 해결과 정보 추출을 돕는 기반 플랫폼입니다.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"LangChain이 무엇인지 한 문장으로 설명해줘\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400dfc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    당신은 AI 튜터입니다.\n",
      "    아래 질문에 대해 한 문장으로 명확하게 한글로 답하세요.\n",
      "    \n",
      "    질문: LangChain이 왜 필요한가?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "#  PromptTemplate과 ChatPromptTemplate은 동일하게 동작하나, 단일문자열 or 역할기반 메시지의 차이임.\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    당신은 AI 튜터입니다.\n",
    "    아래 질문에 대해 한 문장으로 명확하게 한글로 답하세요.\n",
    "    \n",
    "    질문: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(question=\"LangChain이 왜 필요한가?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c85e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ontology는 정보의 구조와 의미를 정의하고 관계를 명확히 하는 체계적인 모델 또는 체계입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 68, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5-3b-instruct-q4_k_m.gguf', 'system_fingerprint': 'b7654-3333951d8', 'id': 'chatcmpl-tbi8iJCUnySyLWL68p0Y9R7NLmqpZUAp', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b9910-2c55-7371-abb8-087b29ff5726-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 33, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(question=\"Ontology가 무엇인가?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc7fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a professional translator.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Translate the following text to Korean:\\nHello world', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional translator.\"),\n",
    "    (\"human\", \"Translate the following text to Korean:\\n{text}\")\n",
    "])\n",
    "\n",
    "prompt.format_messages(text=\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4470be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello is translated to Korean as \"안녕하세요\" (annyeonghaseyo).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5-3b-instruct-q4_k_m.gguf', 'system_fingerprint': 'b7654-3333951d8', 'id': 'chatcmpl-35YCXEEKqwVgBlEvPOvzHZw5rhFcVcqm', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b990d-dc2d-7a02-98ac-c57413dea261-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 27, 'output_tokens': 21, 'total_tokens': 48, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"text\": \"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다. 독도는 경상북도 울릉군에 속해 있으며, 대한민국의 영토입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# messages = chat_prompt.invoke(\n",
    "#     {\"question\": \"LangChain은 무엇인가요?\"}\n",
    "# )\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "response = chain.invoke({\"question\": \"독도는 어느 나라 땅 인가요?\"})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534b7ae",
   "metadata": {},
   "source": [
    "StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다. 독도는 경상북도 울릉군에 속해 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# outputparser 추가\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | output_parser\n",
    "result = chain.invoke({\"question\": \"독도는 어느 나라 땅 인가요?\"})\n",
    "\n",
    "print(result)       # 출력은 문자열(content 속성 없음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9042af7",
   "metadata": {},
   "source": [
    "RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41082f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독도는 대한민국의 땅입니다. 독도는 경상북도 울릉군에 속해 있으며, 대한민국의 영토입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 지리학자입니다.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | chat_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"독도는 어느 나라 땅 인가요?\")     # {\"question\": \"...\"} 형태로 감싸지 않음 → RunnablePassthrough에서 다음 단계로 그대로 전달\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd5a18",
   "metadata": {},
   "source": [
    "OutputParser 활용 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'country': '대한민국', 'island_name': '독도', 'coordinates': {'latitude': '36.2500', 'longitude': '126.8000'}}, 'history': {'establishment': '1416년', 'establisher': '조선 왕조', 'significance': '국土의 확장과 통일의象征'}, 'current_status': {'administered_by': '대한민국 정부', 'accessibility': '독도는 현재 일반 관광객의 접근이 제한됩니다.'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 정보를 JSON으로만 출력하는 AI입니다.\"),\n",
    "    (\"user\", \"질문에 답하세요.\\n\\n{format_instructions}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "chain = json_prompt | llm | parser \n",
    "result = chain.invoke(\n",
    "    {\"question\": \"독도는 어느 나라 땅 인가요? 국가와 위치, 역사 등을 포함해서 알려주세요.\",\n",
    "     \"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 결과를 보면 알 수 있듯이, llm이 판단하여 JSON 형식으로 출력을 생성함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce70a92",
   "metadata": {},
   "source": [
    "Pydantic OutputParser (Custom Setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80780e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: LangChain의 역할은 자연어 처리(NLP)와 인공지능(AI)을 통합하여 사용자와 AI 간의 대화형 인터페이스를 개선하는 데 중점을 둔다. 이를 통해 AI가 사용자의 요청에 대한 자연스러운 대화를 생성하고, 사용자가 제공한 정보를 처리하여 필요한 결과를 제공할 수 있도록 한다.\n\nLangChain은 다양한 NLP 모듈과 기능을 제공하여 AI가 사용자의 요청을 이해하고 대답하는 데 필요한 정보를 추출하고 처리할 수 있도록 한다. 이를 통해 AI는 사용자의 요청을 이해하고, 필요한 정보를 추출하고, 이를 바탕으로 답변을 생성할 수 있다.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\output_parsers\\json.py:84\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\utils\\json.py:164\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    163\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\utils\\json.py:194\u001b[0m, in \u001b[0;36m_parse_json\u001b[1;34m(json_str, parser)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\utils\\json.py:137\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[1;34m(s, strict)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.18-windows-x86_64-none\\lib\\json\\__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.18-windows-x86_64-none\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.18-windows-x86_64-none\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m출력을 반드시 지정된 형식으로 작성하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     18\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m질문: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m ])\n\u001b[0;32m     21\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m parser\n\u001b[1;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLangChain의 역할을 설명해줘\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat_instructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_format_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(result))\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3151\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3149\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3150\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3151\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3152\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:201\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m--> 201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    212\u001b[0m         config,\n\u001b[0;32m    213\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     )\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2056\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2057\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2058\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2059\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2060\u001b[0m                 func,\n\u001b[0;32m   2061\u001b[0m                 input_,\n\u001b[0;32m   2062\u001b[0m                 config,\n\u001b[0;32m   2063\u001b[0m                 run_manager,\n\u001b[0;32m   2064\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2065\u001b[0m             ),\n\u001b[0;32m   2066\u001b[0m         )\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2068\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\runnables\\config.py:435\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    434\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:202\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 202\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    205\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    206\u001b[0m             config,\n\u001b[0;32m    207\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    208\u001b[0m         )\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    212\u001b[0m         config,\n\u001b[0;32m    213\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     )\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:74\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse the result of an LLM call to a Pydantic object.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    The parsed Pydantic object.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_obj(json_object)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "File \u001b[1;32md:\\llm_serving\\.venv\\lib\\site-packages\\langchain_core\\output_parsers\\json.py:87\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     86\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Invalid json output: LangChain의 역할은 자연어 처리(NLP)와 인공지능(AI)을 통합하여 사용자와 AI 간의 대화형 인터페이스를 개선하는 데 중점을 둔다. 이를 통해 AI가 사용자의 요청에 대한 자연스러운 대화를 생성하고, 사용자가 제공한 정보를 처리하여 필요한 결과를 제공할 수 있도록 한다.\n\nLangChain은 다양한 NLP 모듈과 기능을 제공하여 AI가 사용자의 요청을 이해하고 대답하는 데 필요한 정보를 추출하고 처리할 수 있도록 한다. 이를 통해 AI는 사용자의 요청을 이해하고, 필요한 정보를 추출하고, 이를 바탕으로 답변을 생성할 수 있다.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "# Pydantic 모델 정의\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    summary: str = Field(description=\"한 문장 요약\")\n",
    "    keywords: list[str] = Field(description=\"핵심 키워드 목록\")\n",
    "\n",
    "\n",
    "# Parser 생성\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Answer)\n",
    "\n",
    "\n",
    "# Prompt 구성\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"출력을 반드시 지정된 형식으로 작성하세요.\"),\n",
    "    (\"user\", \"{format_instructions}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"question\": \"LangChain의 역할을 설명해줘\",\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef245ec8",
   "metadata": {},
   "source": [
    "SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a4ecc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AI': {'Strengths': [{'Name': 'Speed and Efficiency', 'Description': 'AI can process and analyze large amounts of data much faster than humans.'}, {'Name': 'Accuracy', 'Description': 'AI can perform tasks with high accuracy and consistency, reducing human error.'}, {'Name': 'Automation', 'Description': 'AI can automate repetitive and time-consuming tasks, freeing up human resources.'}, {'Name': 'Insight and Pattern Recognition', 'Description': 'AI can identify patterns and insights in data that might be difficult for humans to detect.'}], 'Weaknesses': [{'Name': 'Lack of Creativity', 'Description': 'AI lacks creativity and cannot generate new ideas or concepts.'}, {'Name': 'Limited Understanding of Context', 'Description': 'AI may struggle with tasks that require understanding of context and human emotions.'}, {'Name': 'Bias and Fairness', 'Description': 'AI systems can be biased if the data they are trained on is biased.'}, {'Name': 'Dependence on Data Quality', 'Description': 'AI systems perform better when trained on high-quality data, which may not always be available.'}]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "chain = chat_prompt | llm | parser\n",
    "\n",
    "result = chain.invoke(\n",
    "    {\"question\": \"AI의 장단점을 JSON으로 정리해줘\"}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d72921cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'thought': ''}\n",
      "{'thought': '독'}\n",
      "{'thought': '독도'}\n",
      "{'thought': '독도는'}\n",
      "{'thought': '독도는 대한'}\n",
      "{'thought': '독도는 대한민'}\n",
      "{'thought': '독도는 대한민국'}\n",
      "{'thought': '독도는 대한민국의'}\n",
      "{'thought': '독도는 대한민국의 땅'}\n",
      "{'thought': '독도는 대한민국의 땅으로'}\n",
      "{'thought': '독도는 대한민국의 땅으로,'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': ''}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅입니다'}\n",
      "{'thought': '독도는 대한민국의 땅으로, 경상북도 울릉군에 속해 있습니다.', 'answer': '독도는 대한민국의 땅입니다.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"반드시 JSON 형식으로만 응답하세요.\"),\n",
    "    (\"user\", \"\"\"\n",
    "질문에 답하세요.\n",
    "\n",
    "JSON 형식:\n",
    "{{\n",
    "  \"thought\": \"...\",\n",
    "  \"answer\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "\n",
    "### 주의! Prompt에 JSON / dict / code block을 넣을 경우 {}는 항상 {{}}로 쓴다(이스케이프) ###\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "for chunk in chain.stream({\"question\": \"독도는 어느 나라 땅 인가요?\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d520f",
   "metadata": {},
   "source": [
    "ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c481e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저축을 늘리기 위해 매달 일정 금액을 자동으로 저축하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# <이전 대화를 포함한 메시지 전달>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 정의: 금융 상담 역할\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 금융 상담사입니다. 사용자에게 최선의 금융 조언을 제공합니다.\"),\n",
    "        (\"placeholder\", \"{messages}\"),  # 대화 이력 추가\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트와 모델을 연결하여 체인 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 이전 대화를 포함한 메시지 전달\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"human\", \"저축을 늘리기 위해 무엇을 할 수 있나요?\"),  # 사용자의 첫 질문\n",
    "            (\"ai\", \"저축 목표를 설정하고, 매달 자동 이체로 일정 금액을 저축하세요.\"),  # 챗봇의 답변\n",
    "            (\"human\", \"방금 뭐라고 했나요?\"),  # 사용자의 재확인 질문\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(ai_msg.content)  # 챗봇의 응답 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5af860ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저축을 늘리기 위해 매달 일정 금액을 자동으로 저축하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# <`ChatMessageHistory`를 사용한 메시지 관리>\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# 대화 이력 저장을 위한 클래스 초기화\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "# 사용자 메시지 추가\n",
    "chat_history.add_user_message(\"저축을 늘리기 위해 무엇을 할 수 있나요?\")\n",
    "chat_history.add_ai_message(\"저축 목표를 설정하고, 매달 자동 이체로 일정 금액을 저축하세요.\")\n",
    "\n",
    "# 새로운 질문 추가 후 다시 체인 실행\n",
    "chat_history.add_user_message(\"방금 뭐라고 했나요?\")\n",
    "ai_response = chain.invoke({\"messages\": chat_history.messages})\n",
    "print(ai_response.content)  # 챗봇은 이전 메시지를 기억하여 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e2ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_serving (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
